{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccffe3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting mlxtend\n",
      "  Obtaining dependency information for mlxtend from https://files.pythonhosted.org/packages/1c/07/512f6a780239ad6ce06ce2aa7b4067583f5ddcfc7703a964a082c706a070/mlxtend-0.23.1-py3-none-any.whl.metadata\n",
      "  Downloading mlxtend-0.23.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (1.11.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (1.3.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (3.7.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Downloading mlxtend-0.23.1-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.2/1.4 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.5/1.4 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.9/1.4 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.1/1.4 MB 5.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.3/1.4 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.3/1.4 MB 4.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.4/1.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.4/1.4 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.4/1.4 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 3.1 MB/s eta 0:00:00\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.1\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3165730c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting faker\n",
      "  Obtaining dependency information for faker from https://files.pythonhosted.org/packages/d6/a9/3bdbd257f7aa3cb971bbf8c688827532ecfe6448168d211cb63b942f6431/Faker-28.4.1-py3-none-any.whl.metadata\n",
      "  Downloading Faker-28.4.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from faker) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
      "Downloading Faker-28.4.1-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.2/1.8 MB 3.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.4/1.8 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 3.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.7/1.8 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/1.8 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.2/1.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.7/1.8 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 4.0 MB/s eta 0:00:00\n",
      "Installing collected packages: faker\n",
      "Successfully installed faker-28.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script faker.exe is installed in 'C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b13a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering Synthetic Data.......\n",
      "Data Gathering Complete\n",
      "Dataset Shape: (100, 10)\n",
      "Performing Apriori algorithm...\n",
      "Apriori algorithm complete. Found 44 rules.\n",
      "Apriori rules visual saved as 'apriori3d.html'\n",
      "Performing K-means...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K-means Clustering:   0%|                                                                      | 0/100 [00:00<?, ?it/s]C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning:\n",
      "\n",
      "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning:\n",
      "\n",
      "KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "\n",
      "K-means Clustering:   1%|▌                                                             | 1/100 [00:02<04:39,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means iteration 0\n",
      "Intermediate visual saved as 'customer_cluster_3d_step0.html'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning:\n",
      "\n",
      "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning:\n",
      "\n",
      "KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "\n",
      "K-means Clustering:   2%|█▏                                                            | 2/100 [00:05<04:09,  2.55s/it]C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning:\n",
      "\n",
      "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning:\n",
      "\n",
      "KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "\n",
      "K-means Clustering:   3%|█▊                                                            | 3/100 [00:07<03:47,  2.34s/it]C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning:\n",
      "\n",
      "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning:\n",
      "\n",
      "KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "\n",
      "K-means Clustering:   4%|██▍                                                           | 4/100 [00:09<03:39,  2.28s/it]C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning:\n",
      "\n",
      "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning:\n",
      "\n",
      "KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "\n",
      "K-means Clustering:   5%|███                                                           | 5/100 [00:11<03:30,  2.22s/it]C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning:\n",
      "\n",
      "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning:\n",
      "\n",
      "KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "\n",
      "K-means Clustering:   6%|███▋                                                          | 6/100 [00:13<03:29,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means iteration 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "K-means Clustering:   6%|███▋                                                          | 6/100 [00:14<03:40,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate visual saved as 'customer_cluster_3d_step1.html'\n",
      "K-means Clustering completed\n",
      "Final customer cluster visual saved as 'customer_cluster_3dfinal.html'\n",
      "Analysis complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "import plotly.graph_objects as go  # Corrected from ploty to plotly\n",
    "from itertools import combinations\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px  # Corrected from ploty to plotly\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(43)\n",
    "random.seed(43)\n",
    "\n",
    "# Create Faker object\n",
    "fake = Faker()\n",
    "\n",
    "def generate_data(num_products=10, num_customers=100, num_transactions=500):\n",
    "    products = [fake.word() for _ in range(num_products)]\n",
    "    transactions = []\n",
    "    for _ in range(num_transactions):\n",
    "        customer_id = random.randint(1, num_customers)\n",
    "        basket_size = random.randint(1, 5)\n",
    "        basket = random.sample(products, basket_size)\n",
    "        transactions.append({'customer_id': customer_id, 'products': basket})\n",
    "\n",
    "    df = pd.DataFrame(transactions)\n",
    "    df_encoded = df.explode('products').pivot_table(\n",
    "        index='customer_id', columns='products',\n",
    "        aggfunc=lambda x: 1, fill_value=0\n",
    "    )\n",
    "    return df_encoded\n",
    "\n",
    "def simple_apriori(df, min_support=0.1, min_confidence=0.5):\n",
    "    def support(item_set):\n",
    "        return (df[list(item_set)].sum(axis=1) == len(item_set)).mean()\n",
    "\n",
    "    items = set(df.columns)\n",
    "    item_sets = [frozenset([item]) for item in items]\n",
    "\n",
    "    rules = []\n",
    "    for k in range(2, len(items) + 1):\n",
    "        item_sets = [s for s in combinations(items, k) if support(s) >= min_support]\n",
    "        for item_set in item_sets:\n",
    "            item_set = frozenset(item_set)\n",
    "            for i in range(1, len(item_set)):\n",
    "                for antecedents in combinations(item_set, i):\n",
    "                    antecedents = frozenset(antecedents)\n",
    "                    consequent = item_set - antecedents\n",
    "                    confidence = support(item_set) / support(antecedents)\n",
    "                    if confidence >= min_confidence:\n",
    "                        lift = confidence / support(consequent)\n",
    "                        rules.append({\n",
    "                            'antecedents': ','.join(antecedents),\n",
    "                            'consequent': ','.join(consequent),\n",
    "                            'support': support(item_set),\n",
    "                            'confidence': confidence,\n",
    "                            'lift': lift\n",
    "                        })\n",
    "\n",
    "                        if len(rules) >= 10:\n",
    "                            break\n",
    "            if len(rules) >= 10:\n",
    "                break\n",
    "    return pd.DataFrame(rules).sort_values('lift', ascending=False)\n",
    "\n",
    "def perform_kmeans(df, n_clusters=3, update_intervals=5):\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=32, max_iter=100)\n",
    "\n",
    "    with tqdm(total=kmeans.max_iter, desc=\"K-means Clustering\") as pbar:\n",
    "        for i in range(kmeans.max_iter):\n",
    "            kmeans.fit(df_scaled)\n",
    "            pbar.update(1)\n",
    "            if i % update_intervals == 0:\n",
    "                yield kmeans.labels_\n",
    "\n",
    "            if kmeans.n_iter_ <= i + 1:\n",
    "                break\n",
    "    return kmeans.labels_\n",
    "\n",
    "def visualize_apriori(rules, top_n=10):\n",
    "    top_rules = rules.head(top_n)\n",
    "    fig = px.scatter_3d(\n",
    "        top_rules, x=\"support\", y=\"confidence\", z='lift',\n",
    "        color='lift', size='support',\n",
    "        hover_name='antecedents', hover_data=['consequent'],\n",
    "        labels={'support': 'Support', 'confidence': \"Confidence\", 'lift': 'Lift'},\n",
    "        title=f\"Top {top_n} Association Rules\"\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "def visualize_kmeans(df, cluster_labels):\n",
    "    pca = PCA(n_components=3)\n",
    "    pca_res = pca.fit_transform(df)\n",
    "\n",
    "    fig = px.scatter_3d(\n",
    "        x=pca_res[:, 0], y=pca_res[:, 1], z=pca_res[:, 2],\n",
    "        color=cluster_labels,\n",
    "        title=\"Customer Cluster Visualization\"\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "def main():\n",
    "    print(\"Gathering Synthetic Data.......\")\n",
    "    df_encoded = generate_data(num_products=10, num_customers=100, num_transactions=500)\n",
    "    print(\"Data Gathering Complete\")\n",
    "    print(f\"Dataset Shape: {df_encoded.shape}\")\n",
    "\n",
    "    print(\"Performing Apriori algorithm...\")\n",
    "    rules = simple_apriori(df_encoded, min_support=0.1, min_confidence=0.5)\n",
    "\n",
    "    if not rules.empty:\n",
    "        print(f\"Apriori algorithm complete. Found {len(rules)} rules.\")\n",
    "        viz = visualize_apriori(rules)\n",
    "        viz.write_html(\"apriori3d.html\")\n",
    "        print(\"Apriori rules visual saved as 'apriori3d.html'\")\n",
    "    else:\n",
    "        print(\"Apriori algorithm failed\")\n",
    "\n",
    "    print(\"Performing K-means...\")\n",
    "    kmeans_gen = perform_kmeans(df_encoded, n_clusters=3, update_intervals=5)\n",
    "    for i, labels in enumerate(kmeans_gen):\n",
    "        print(f\"K-means iteration {i * 5}\")\n",
    "        viz = visualize_kmeans(df_encoded, labels)\n",
    "        viz.write_html(f\"customer_cluster_3d_step{i}.html\")\n",
    "        print(f\"Intermediate visual saved as 'customer_cluster_3d_step{i}.html'\")\n",
    "\n",
    "    final_labels = labels\n",
    "    print(\"K-means Clustering completed\")\n",
    "    final_viz = visualize_kmeans(df_encoded, final_labels)\n",
    "    final_viz.write_html(\"customer_cluster_3dfinal.html\")\n",
    "    print(\"Final customer cluster visual saved as 'customer_cluster_3dfinal.html'\")\n",
    "\n",
    "    print(\"Analysis complete\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379744b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
